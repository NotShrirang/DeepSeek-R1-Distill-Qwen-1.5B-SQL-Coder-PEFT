{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets evaluate bitsandbytes optimum peft","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!accelerate config default","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, Subset\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, AdamW, BitsAndBytesConfig\nfrom accelerate import Accelerator\nimport torch.distributed as dist\nfrom torch.distributed.fsdp import FullyShardedDataParallel as FSDP\nfrom peft import LoraConfig, get_peft_model\nimport tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:22.268557Z","iopub.execute_input":"2025-02-23T03:53:22.268784Z","iopub.status.idle":"2025-02-23T03:53:29.549458Z","shell.execute_reply.started":"2025-02-23T03:53:22.268763Z","shell.execute_reply":"2025-02-23T03:53:29.548660Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:29.573984Z","iopub.execute_input":"2025-02-23T03:53:29.574285Z","iopub.status.idle":"2025-02-23T03:53:29.577880Z","shell.execute_reply.started":"2025-02-23T03:53:29.574256Z","shell.execute_reply":"2025-02-23T03:53:29.577011Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"torch.set_float32_matmul_precision('high')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:29.580663Z","iopub.execute_input":"2025-02-23T03:53:29.580928Z","iopub.status.idle":"2025-02-23T03:53:29.585941Z","shell.execute_reply.started":"2025-02-23T03:53:29.580908Z","shell.execute_reply":"2025-02-23T03:53:29.585077Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"accelerator = Accelerator(mixed_precision=\"bf16\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:29.586875Z","iopub.execute_input":"2025-02-23T03:53:29.587159Z","iopub.status.idle":"2025-02-23T03:53:29.831682Z","shell.execute_reply.started":"2025-02-23T03:53:29.587130Z","shell.execute_reply":"2025-02-23T03:53:29.830733Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"subset_indices = list(range(256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:29.834867Z","iopub.execute_input":"2025-02-23T03:53:29.835090Z","iopub.status.idle":"2025-02-23T03:53:29.838511Z","shell.execute_reply.started":"2025-02-23T03:53:29.835069Z","shell.execute_reply":"2025-02-23T03:53:29.837723Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"training_ds = load_dataset(\"gretelai/synthetic_text_to_sql\", split=\"train\")\nvalid_ds = load_dataset(\"gretelai/synthetic_text_to_sql\", split=\"test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:29.839354Z","iopub.execute_input":"2025-02-23T03:53:29.839667Z","iopub.status.idle":"2025-02-23T03:53:31.016790Z","shell.execute_reply.started":"2025-02-23T03:53:29.839618Z","shell.execute_reply":"2025-02-23T03:53:31.015901Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"valid_ds = Subset(valid_ds, subset_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:31.017703Z","iopub.execute_input":"2025-02-23T03:53:31.018013Z","iopub.status.idle":"2025-02-23T03:53:31.021769Z","shell.execute_reply.started":"2025-02-23T03:53:31.017984Z","shell.execute_reply":"2025-02-23T03:53:31.020856Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"training_ds[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:31.022474Z","iopub.execute_input":"2025-02-23T03:53:31.022761Z","iopub.status.idle":"2025-02-23T03:53:31.039002Z","shell.execute_reply.started":"2025-02-23T03:53:31.022740Z","shell.execute_reply":"2025-02-23T03:53:31.038234Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'id': 5097,\n 'domain': 'forestry',\n 'domain_description': 'Comprehensive data on sustainable forest management, timber production, wildlife habitat, and carbon sequestration in forestry.',\n 'sql_complexity': 'single join',\n 'sql_complexity_description': 'only one join (specify inner, outer, cross)',\n 'sql_task_type': 'analytics and reporting',\n 'sql_task_type_description': 'generating reports, dashboards, and analytical insights',\n 'sql_prompt': 'What is the total volume of timber sold by each salesperson, sorted by salesperson?',\n 'sql_context': \"CREATE TABLE salesperson (salesperson_id INT, name TEXT, region TEXT); INSERT INTO salesperson (salesperson_id, name, region) VALUES (1, 'John Doe', 'North'), (2, 'Jane Smith', 'South'); CREATE TABLE timber_sales (sales_id INT, salesperson_id INT, volume REAL, sale_date DATE); INSERT INTO timber_sales (sales_id, salesperson_id, volume, sale_date) VALUES (1, 1, 120, '2021-01-01'), (2, 1, 150, '2021-02-01'), (3, 2, 180, '2021-01-01');\",\n 'sql': 'SELECT salesperson_id, name, SUM(volume) as total_volume FROM timber_sales JOIN salesperson ON timber_sales.salesperson_id = salesperson.salesperson_id GROUP BY salesperson_id, name ORDER BY total_volume DESC;',\n 'sql_explanation': 'Joins timber_sales and salesperson tables, groups sales by salesperson, calculates total volume sold by each salesperson, and orders the results by total volume in descending order.'}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:31.039875Z","iopub.execute_input":"2025-02-23T03:53:31.040160Z","iopub.status.idle":"2025-02-23T03:53:31.049835Z","shell.execute_reply.started":"2025-02-23T03:53:31.040132Z","shell.execute_reply":"2025-02-23T03:53:31.048996Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"torch.backends.cuda.matmul.allow_tf32 = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:31.050711Z","iopub.execute_input":"2025-02-23T03:53:31.050969Z","iopub.status.idle":"2025-02-23T03:53:31.061666Z","shell.execute_reply.started":"2025-02-23T03:53:31.050942Z","shell.execute_reply":"2025-02-23T03:53:31.061042Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:31.062504Z","iopub.execute_input":"2025-02-23T03:53:31.062787Z","iopub.status.idle":"2025-02-23T03:53:31.074171Z","shell.execute_reply.started":"2025-02-23T03:53:31.062759Z","shell.execute_reply":"2025-02-23T03:53:31.073512Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:31.075795Z","iopub.execute_input":"2025-02-23T03:53:31.075989Z","iopub.status.idle":"2025-02-23T03:53:31.085329Z","shell.execute_reply.started":"2025-02-23T03:53:31.075973Z","shell.execute_reply":"2025-02-23T03:53:31.084634Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n    torch_dtype=torch.bfloat16,\n    quantization_config=bnb_config,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:31.400463Z","iopub.execute_input":"2025-02-23T03:53:31.400813Z","iopub.status.idle":"2025-02-23T03:53:34.337031Z","shell.execute_reply.started":"2025-02-23T03:53:31.400782Z","shell.execute_reply":"2025-02-23T03:53:34.336355Z"}},"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:36.052948Z","iopub.execute_input":"2025-02-23T03:53:36.053257Z","iopub.status.idle":"2025-02-23T03:53:36.149385Z","shell.execute_reply.started":"2025-02-23T03:53:36.053232Z","shell.execute_reply":"2025-02-23T03:53:36.148732Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:38.748376Z","iopub.execute_input":"2025-02-23T03:53:38.748687Z","iopub.status.idle":"2025-02-23T03:53:38.753146Z","shell.execute_reply.started":"2025-02-23T03:53:38.748645Z","shell.execute_reply":"2025-02-23T03:53:38.752332Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:38.962129Z","iopub.execute_input":"2025-02-23T03:53:38.962372Z","iopub.status.idle":"2025-02-23T03:53:38.966271Z","shell.execute_reply.started":"2025-02-23T03:53:38.962351Z","shell.execute_reply":"2025-02-23T03:53:38.965332Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:41.795805Z","iopub.execute_input":"2025-02-23T03:53:41.796108Z","iopub.status.idle":"2025-02-23T03:53:41.800869Z","shell.execute_reply.started":"2025-02-23T03:53:41.796086Z","shell.execute_reply":"2025-02-23T03:53:41.800146Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:42.300826Z","iopub.execute_input":"2025-02-23T03:53:42.301117Z","iopub.status.idle":"2025-02-23T03:53:42.547822Z","shell.execute_reply.started":"2025-02-23T03:53:42.301091Z","shell.execute_reply":"2025-02-23T03:53:42.546965Z"}},"outputs":[{"name":"stdout","text":"Sun Feb 23 03:53:42 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   57C    P0             28W /   70W |    1691MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   49C    P8             12W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"def collate_fn(batch):\n    \"\"\" Tokenizes and dynamically pads a batch of text samples. \"\"\"\n    system_prompt = \"You are an AI that translates natural language into SQL queries. You will output only the SQL query that outputs the following natural language question.\"\n    sql_pairs = [f\"{system_prompt}\\nQuestion:\\n{example['sql_prompt']} {tokenizer.eos_token}\\n SQL Query:\\n{example['sql']}\" for example in batch]\n\n    tokenized = tokenizer(sql_pairs, padding=True, truncation=True, return_tensors=\"pt\")\n\n    input_ids = tokenized[\"input_ids\"]\n    attention_mask = tokenized[\"attention_mask\"]\n\n    labels = input_ids.clone()\n    labels[labels == tokenizer.pad_token_id] = -100\n\n    return {\n        \"input_ids\": input_ids.to(device),\n        \"attention_mask\": attention_mask.to(device),\n        \"labels\": labels.to(device),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:46.084703Z","iopub.execute_input":"2025-02-23T03:53:46.085032Z","iopub.status.idle":"2025-02-23T03:53:46.090916Z","shell.execute_reply.started":"2025-02-23T03:53:46.085007Z","shell.execute_reply":"2025-02-23T03:53:46.089917Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"training_ds.set_format(type=\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:49.520208Z","iopub.execute_input":"2025-02-23T03:53:49.520539Z","iopub.status.idle":"2025-02-23T03:53:49.525007Z","shell.execute_reply.started":"2025-02-23T03:53:49.520512Z","shell.execute_reply":"2025-02-23T03:53:49.524263Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"train_dataloader = DataLoader(training_ds, batch_size=4, collate_fn=collate_fn, shuffle=True)\nvalid_dataloader = DataLoader(valid_ds, batch_size=4, collate_fn=collate_fn, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:59.143164Z","iopub.execute_input":"2025-02-23T03:53:59.143483Z","iopub.status.idle":"2025-02-23T03:53:59.147758Z","shell.execute_reply.started":"2025-02-23T03:53:59.143458Z","shell.execute_reply":"2025-02-23T03:53:59.146945Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:53:59.519852Z","iopub.execute_input":"2025-02-23T03:53:59.520082Z","iopub.status.idle":"2025-02-23T03:53:59.526923Z","shell.execute_reply.started":"2025-02-23T03:53:59.520062Z","shell.execute_reply":"2025-02-23T03:53:59.526017Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"num_epochs = 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:54:00.482394Z","iopub.execute_input":"2025-02-23T03:54:00.482729Z","iopub.status.idle":"2025-02-23T03:54:00.486502Z","shell.execute_reply.started":"2025-02-23T03:54:00.482704Z","shell.execute_reply":"2025-02-23T03:54:00.485608Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"gradient_accumulation_steps = 4\nbatch_size = 1\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nfor param in model.parameters():\n    param.data = param.data.to(device)\n    if param.grad is not None:\n        param.grad.data = param.grad.data.to(device)\n\nimport bitsandbytes as bnb\nfor name, module in model.named_modules():\n    if isinstance(module, bnb.nn.Linear4bit):\n        module.to(device)\n\nfor step, batch in tqdm.notebook.tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n    batch = {k: v.to(device) for k, v in batch.items()}\n    \n    outputs = model(**batch)\n    loss = outputs.loss\n    loss = loss / gradient_accumulation_steps\n\n    loss.mean().backward()\n\n    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n    if (step + 1) % gradient_accumulation_steps == 0:\n        optimizer.step()\n        optimizer.zero_grad()\n\n    if (step + 1) % 1000 == 0:\n        training_loss = loss.item() * 4\n        \n        model.eval()\n        total_loss = 0\n\n        for val_step, val_batch in tqdm.notebook.tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n            val_batch = {k: v.to(device) for k, v in val_batch.items()}\n            with torch.no_grad():\n                val_outputs = model(**val_batch)\n                val_loss = val_outputs.loss\n                total_loss += val_loss.mean().item()\n\n        avg_loss = total_loss / len(valid_dataloader)\n        print(f\"Training Loss at Step {step+1}, Loss: {training_loss:.4f}\")\n        print(f\"Validation Loss at Step {step+1}, Loss: {avg_loss:.4f}\")\n\n        model.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T03:54:30.991943Z","iopub.execute_input":"2025-02-23T03:54:30.992256Z","iopub.status.idle":"2025-02-23T14:24:21.191339Z","shell.execute_reply.started":"2025-02-23T03:54:30.992233Z","shell.execute_reply":"2025-02-23T14:24:21.190332Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad7e997e44d14ef6a07a51d7a0db8a85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4d3a4869ba34b2088e6e66e07a1b355"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 1000, Loss: 1.0017\nValidation Loss at Step 1000, Loss: 1.0256\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50d162066dda4c0881dc5b974efe1e80"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 2000, Loss: 1.1644\nValidation Loss at Step 2000, Loss: 0.8818\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"659d9a5df7ef496296b95d0d8c8e6296"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 3000, Loss: 0.7851\nValidation Loss at Step 3000, Loss: 0.8507\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f17397931d9449181ac8848bf13d21e"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 4000, Loss: 0.7416\nValidation Loss at Step 4000, Loss: 0.8322\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc5d3e5068a2404eba6f9d01ce0591d6"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 5000, Loss: 0.6960\nValidation Loss at Step 5000, Loss: 0.8184\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7226c787a600485086c4a22b9f2dd679"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 6000, Loss: 1.0118\nValidation Loss at Step 6000, Loss: 0.8068\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3805855aa1d14d92b79ee91281c0ec9d"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 7000, Loss: 0.9897\nValidation Loss at Step 7000, Loss: 0.7997\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7220a40ee9b34e198c80d938ac18fd3f"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 8000, Loss: 0.9165\nValidation Loss at Step 8000, Loss: 0.7938\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52319207465d4522b2d02e9829398616"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 9000, Loss: 0.8048\nValidation Loss at Step 9000, Loss: 0.7875\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52ecb9f7f5d64c949a25fa2e4902763d"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 10000, Loss: 0.8869\nValidation Loss at Step 10000, Loss: 0.7822\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0705397255cb45509cf15a018a8faee1"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 11000, Loss: 0.8387\nValidation Loss at Step 11000, Loss: 0.7788\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c8f851338fd4ce9b938e1aa05df63ec"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 12000, Loss: 0.8117\nValidation Loss at Step 12000, Loss: 0.7746\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b972288b9824ab5b96171c0e4ddb6f7"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 13000, Loss: 0.7259\nValidation Loss at Step 13000, Loss: 0.7719\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"292ea909e920455d9aecdd378653f496"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 14000, Loss: 0.8100\nValidation Loss at Step 14000, Loss: 0.7678\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d87a487cdb7a4ac3896e3c3be98abb73"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 15000, Loss: 0.6901\nValidation Loss at Step 15000, Loss: 0.7626\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e563004f8d814b2885714899e11eb938"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 16000, Loss: 0.9630\nValidation Loss at Step 16000, Loss: 0.7600\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ef6ed2d76704d8ba40354c83d3849eb"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 17000, Loss: 0.6599\nValidation Loss at Step 17000, Loss: 0.7571\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e58d12319eab46178c8242ec109cffe9"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 18000, Loss: 0.6770\nValidation Loss at Step 18000, Loss: 0.7541\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5da8501ed4ad4559bbfb8943ba242867"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 19000, Loss: 0.7360\nValidation Loss at Step 19000, Loss: 0.7509\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be37e93e225c46289e9de9434197ff8c"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 20000, Loss: 0.7170\nValidation Loss at Step 20000, Loss: 0.7458\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eacb4d339084153ae79b3ed4ce7caea"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 21000, Loss: 0.7993\nValidation Loss at Step 21000, Loss: 0.7446\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab685024e990477dbf34ad82dd58da80"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 22000, Loss: 0.5846\nValidation Loss at Step 22000, Loss: 0.7412\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db4675deb67544568ee3df96946f021c"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 23000, Loss: 0.8269\nValidation Loss at Step 23000, Loss: 0.7411\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dba352aa4d7545a39b4e9f0f965d2ea3"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 24000, Loss: 0.5817\nValidation Loss at Step 24000, Loss: 0.7379\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c17d545a71749288439efde83f027d3"}},"metadata":{}},{"name":"stdout","text":"Training Loss at Step 25000, Loss: 0.5772\nValidation Loss at Step 25000, Loss: 0.7357\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"def generate_text(model, tokenizer, prompt, max_new_tokens=100, device=\"cuda\"):\n    \"\"\"Generates text from a given prompt using an autoregressive model.\"\"\"\n    system_prompt = \"You are an AI that translates natural language into SQL queries. You will output only the SQL query that outputs the following natural language question.\"\n    prompt = f\"{system_prompt}\\nQuestion:\\n{prompt} {tokenizer.eos_token}\\n SQL Query:\\n\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n\n    with torch.no_grad():\n        output_ids = model.generate(\n            input_ids=inputs[\"input_ids\"],\n            attention_mask=inputs[\"attention_mask\"],\n            max_new_tokens=max_new_tokens,\n            do_sample=True,\n            temperature=0.7,\n            top_p=0.9,\n            repetition_penalty=1.2,\n            pad_token_id=tokenizer.pad_token_id,\n            eos_token_id=tokenizer.eos_token_id\n        )\n\n    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    \n    return generated_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T14:24:46.870100Z","iopub.execute_input":"2025-02-23T14:24:46.870422Z","iopub.status.idle":"2025-02-23T14:24:46.876478Z","shell.execute_reply.started":"2025-02-23T14:24:46.870397Z","shell.execute_reply":"2025-02-23T14:24:46.875341Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"prompt = \"Write a SQL query to get the total volume of timber sold by each salesperson, sorted by salesperson?\"\ngenerated_output = generate_text(model, tokenizer, prompt, max_new_tokens=200)\n\nprint(\"Generated Text:\\n\", generated_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T14:24:48.840607Z","iopub.execute_input":"2025-02-23T14:24:48.840963Z","iopub.status.idle":"2025-02-23T14:25:03.590106Z","shell.execute_reply.started":"2025-02-23T14:24:48.840936Z","shell.execute_reply":"2025-02-23T14:25:03.589244Z"}},"outputs":[{"name":"stdout","text":"Generated Text:\n You are an AI that translates natural language into SQL queries. You will output only the SQL query that outputs the following natural language question.\nQuestion:\nWrite a SQL query to get the total volume of timber sold by each salesperson, sorted by salesperson? \n SQL Query:\nSELECT s.name, SUM(s.volume) as total_volume FROM sales s GROUP BY s.name ORDER BY s.name; SELECT * FROM sales WHERE state = 'South'; -- To ensure this data is not being modified or altered for some reason: DELETE FROM sales WHERE state = 'North' AND id NOT IN (SELECT id FROM sales WHERE state = 'South'); INSERT INTO sales (state, name, volume) VALUES ('West', 'John Smith', 100); DELETE FROM sales WHERE state = 'East'; INSERT INTO sales (state, name, volume) VALUES ('South', 'Jane Doe', 250); INSERT INTO sales (state, name, volume) VALUES ('Midwest', 'Bob Johnson', 375); INSERT INTO sales (state, name, volume) VALUES ('Northeast', 'Sarah Miller', 400); INSERT INTO sales (state, name, volume) VALUES ('Central', 'Eva Brown', 896); INSERT\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"model.save_pretrained(\"DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT\")\ntokenizer.save_pretrained(\"DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T14:25:19.523929Z","iopub.execute_input":"2025-02-23T14:25:19.524277Z","iopub.status.idle":"2025-02-23T14:25:19.873170Z","shell.execute_reply.started":"2025-02-23T14:25:19.524250Z","shell.execute_reply":"2025-02-23T14:25:19.872282Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"('DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT/tokenizer_config.json',\n 'DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT/special_tokens_map.json',\n 'DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT/tokenizer.json')"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"from huggingface_hub import HfApi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T14:25:27.846036Z","iopub.execute_input":"2025-02-23T14:25:27.846358Z","iopub.status.idle":"2025-02-23T14:25:27.850259Z","shell.execute_reply.started":"2025-02-23T14:25:27.846333Z","shell.execute_reply":"2025-02-23T14:25:27.849514Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"HF_TOKEN = \"\"\n\nrepo_name = \"NotShrirang/DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT\"\napi = HfApi(token=HF_TOKEN)\napi.create_repo(repo_id=repo_name, exist_ok=True)\n\nmodel.push_to_hub(repo_name, token=HF_TOKEN)\ntokenizer.push_to_hub(repo_name, token=HF_TOKEN)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T14:25:36.744324Z","iopub.execute_input":"2025-02-23T14:25:36.744687Z","iopub.status.idle":"2025-02-23T14:25:40.579728Z","shell.execute_reply.started":"2025-02-23T14:25:36.744633Z","shell.execute_reply":"2025-02-23T14:25:40.579010Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e021afa7b2184dd2aba4c616770f615f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/8.73M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"796689df5e00495e8d35f322437c4274"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/NotShrirang/DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT/commit/04d092027d97ef78cbee42979939562b1e15ba7c', commit_message='Upload tokenizer', commit_description='', oid='04d092027d97ef78cbee42979939562b1e15ba7c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/NotShrirang/DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT', endpoint='https://huggingface.co', repo_type='model', repo_id='NotShrirang/DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":36}]}