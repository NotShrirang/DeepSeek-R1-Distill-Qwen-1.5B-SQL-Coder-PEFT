{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install datasets evaluate bitsandbytes optimum peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/shrirang/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    }
   ],
   "source": [
    "!accelerate config default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:22.268784Z",
     "iopub.status.busy": "2025-02-23T03:53:22.268557Z",
     "iopub.status.idle": "2025-02-23T03:53:29.549458Z",
     "shell.execute_reply": "2025-02-23T03:53:29.548660Z",
     "shell.execute_reply.started": "2025-02-23T03:53:22.268763Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW, BitsAndBytesConfig\n",
    "from accelerate import Accelerator\n",
    "import torch.distributed as dist\n",
    "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:29.574285Z",
     "iopub.status.busy": "2025-02-23T03:53:29.573984Z",
     "iopub.status.idle": "2025-02-23T03:53:29.577880Z",
     "shell.execute_reply": "2025-02-23T03:53:29.577011Z",
     "shell.execute_reply.started": "2025-02-23T03:53:29.574256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:29.580928Z",
     "iopub.status.busy": "2025-02-23T03:53:29.580663Z",
     "iopub.status.idle": "2025-02-23T03:53:29.585941Z",
     "shell.execute_reply": "2025-02-23T03:53:29.585077Z",
     "shell.execute_reply.started": "2025-02-23T03:53:29.580908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:29.587159Z",
     "iopub.status.busy": "2025-02-23T03:53:29.586875Z",
     "iopub.status.idle": "2025-02-23T03:53:29.831682Z",
     "shell.execute_reply": "2025-02-23T03:53:29.830733Z",
     "shell.execute_reply.started": "2025-02-23T03:53:29.587130Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "accelerator = Accelerator(mixed_precision=\"bf16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:29.835090Z",
     "iopub.status.busy": "2025-02-23T03:53:29.834867Z",
     "iopub.status.idle": "2025-02-23T03:53:29.838511Z",
     "shell.execute_reply": "2025-02-23T03:53:29.837723Z",
     "shell.execute_reply.started": "2025-02-23T03:53:29.835069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "subset_indices = list(range(256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:29.839667Z",
     "iopub.status.busy": "2025-02-23T03:53:29.839354Z",
     "iopub.status.idle": "2025-02-23T03:53:31.016790Z",
     "shell.execute_reply": "2025-02-23T03:53:31.015901Z",
     "shell.execute_reply.started": "2025-02-23T03:53:29.839618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_ds = load_dataset(\"gretelai/synthetic_text_to_sql\", split=\"train\")\n",
    "valid_ds = load_dataset(\"gretelai/synthetic_text_to_sql\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:31.018013Z",
     "iopub.status.busy": "2025-02-23T03:53:31.017703Z",
     "iopub.status.idle": "2025-02-23T03:53:31.021769Z",
     "shell.execute_reply": "2025-02-23T03:53:31.020856Z",
     "shell.execute_reply.started": "2025-02-23T03:53:31.017984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "valid_ds = Subset(valid_ds, subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:31.022761Z",
     "iopub.status.busy": "2025-02-23T03:53:31.022474Z",
     "iopub.status.idle": "2025-02-23T03:53:31.039002Z",
     "shell.execute_reply": "2025-02-23T03:53:31.038234Z",
     "shell.execute_reply.started": "2025-02-23T03:53:31.022740Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 5097,\n",
       " 'domain': 'forestry',\n",
       " 'domain_description': 'Comprehensive data on sustainable forest management, timber production, wildlife habitat, and carbon sequestration in forestry.',\n",
       " 'sql_complexity': 'single join',\n",
       " 'sql_complexity_description': 'only one join (specify inner, outer, cross)',\n",
       " 'sql_task_type': 'analytics and reporting',\n",
       " 'sql_task_type_description': 'generating reports, dashboards, and analytical insights',\n",
       " 'sql_prompt': 'What is the total volume of timber sold by each salesperson, sorted by salesperson?',\n",
       " 'sql_context': \"CREATE TABLE salesperson (salesperson_id INT, name TEXT, region TEXT); INSERT INTO salesperson (salesperson_id, name, region) VALUES (1, 'John Doe', 'North'), (2, 'Jane Smith', 'South'); CREATE TABLE timber_sales (sales_id INT, salesperson_id INT, volume REAL, sale_date DATE); INSERT INTO timber_sales (sales_id, salesperson_id, volume, sale_date) VALUES (1, 1, 120, '2021-01-01'), (2, 1, 150, '2021-02-01'), (3, 2, 180, '2021-01-01');\",\n",
       " 'sql': 'SELECT salesperson_id, name, SUM(volume) as total_volume FROM timber_sales JOIN salesperson ON timber_sales.salesperson_id = salesperson.salesperson_id GROUP BY salesperson_id, name ORDER BY total_volume DESC;',\n",
       " 'sql_explanation': 'Joins timber_sales and salesperson tables, groups sales by salesperson, calculates total volume sold by each salesperson, and orders the results by total volume in descending order.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:31.040160Z",
     "iopub.status.busy": "2025-02-23T03:53:31.039875Z",
     "iopub.status.idle": "2025-02-23T03:53:31.049835Z",
     "shell.execute_reply": "2025-02-23T03:53:31.048996Z",
     "shell.execute_reply.started": "2025-02-23T03:53:31.040132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:31.050969Z",
     "iopub.status.busy": "2025-02-23T03:53:31.050711Z",
     "iopub.status.idle": "2025-02-23T03:53:31.061666Z",
     "shell.execute_reply": "2025-02-23T03:53:31.061042Z",
     "shell.execute_reply.started": "2025-02-23T03:53:31.050942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:31.062787Z",
     "iopub.status.busy": "2025-02-23T03:53:31.062504Z",
     "iopub.status.idle": "2025-02-23T03:53:31.074171Z",
     "shell.execute_reply": "2025-02-23T03:53:31.073512Z",
     "shell.execute_reply.started": "2025-02-23T03:53:31.062759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\"\n",
    "# )\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:31.075989Z",
     "iopub.status.busy": "2025-02-23T03:53:31.075795Z",
     "iopub.status.idle": "2025-02-23T03:53:31.085329Z",
     "shell.execute_reply": "2025-02-23T03:53:31.084634Z",
     "shell.execute_reply.started": "2025-02-23T03:53:31.075973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:31.400813Z",
     "iopub.status.busy": "2025-02-23T03:53:31.400463Z",
     "iopub.status.idle": "2025-02-23T03:53:34.337031Z",
     "shell.execute_reply": "2025-02-23T03:53:34.336355Z",
     "shell.execute_reply.started": "2025-02-23T03:53:31.400782Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:36.053257Z",
     "iopub.status.busy": "2025-02-23T03:53:36.052948Z",
     "iopub.status.idle": "2025-02-23T03:53:36.149385Z",
     "shell.execute_reply": "2025-02-23T03:53:36.148732Z",
     "shell.execute_reply.started": "2025-02-23T03:53:36.053232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:38.748687Z",
     "iopub.status.busy": "2025-02-23T03:53:38.748376Z",
     "iopub.status.idle": "2025-02-23T03:53:38.753146Z",
     "shell.execute_reply": "2025-02-23T03:53:38.752332Z",
     "shell.execute_reply.started": "2025-02-23T03:53:38.748645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:38.962372Z",
     "iopub.status.busy": "2025-02-23T03:53:38.962129Z",
     "iopub.status.idle": "2025-02-23T03:53:38.966271Z",
     "shell.execute_reply": "2025-02-23T03:53:38.965332Z",
     "shell.execute_reply.started": "2025-02-23T03:53:38.962351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:41.796108Z",
     "iopub.status.busy": "2025-02-23T03:53:41.795805Z",
     "iopub.status.idle": "2025-02-23T03:53:41.800869Z",
     "shell.execute_reply": "2025-02-23T03:53:41.800146Z",
     "shell.execute_reply.started": "2025-02-23T03:53:41.796086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:42.301117Z",
     "iopub.status.busy": "2025-02-23T03:53:42.300826Z",
     "iopub.status.idle": "2025-02-23T03:53:42.547822Z",
     "shell.execute_reply": "2025-02-23T03:53:42.546965Z",
     "shell.execute_reply.started": "2025-02-23T03:53:42.301091Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 24 18:51:45 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A4000               Off |   00000000:03:00.0  On |                    0 |\n",
      "| 41%   37C    P5             19W /  140W |     747MiB /  15352MiB |     21%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     59233      G   /usr/lib/xorg/Xorg                            237MiB |\n",
      "|    0   N/A  N/A     59677      G   /usr/bin/gnome-shell                          169MiB |\n",
      "|    0   N/A  N/A     65331      G   ...onEnabled --variations-seed-version         43MiB |\n",
      "|    0   N/A  N/A     67699      G   ...erProcess --variations-seed-version        244MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:46.085032Z",
     "iopub.status.busy": "2025-02-23T03:53:46.084703Z",
     "iopub.status.idle": "2025-02-23T03:53:46.090916Z",
     "shell.execute_reply": "2025-02-23T03:53:46.089917Z",
     "shell.execute_reply.started": "2025-02-23T03:53:46.085007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\" Tokenizes and dynamically pads a batch of text samples. \"\"\"\n",
    "    system_prompt = \"You are an AI that translates natural language into SQL queries. You will output only the SQL query that outputs the following natural language question.\"\n",
    "    sql_pairs = [f\"{system_prompt}\\n\\nQuestion:\\n{example['sql_prompt']} {tokenizer.eos_token}\\n SQL Query:\\n{example['sql']}\" for example in batch]\n",
    "\n",
    "    tokenized = tokenizer(sql_pairs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    input_ids = tokenized[\"input_ids\"]\n",
    "    attention_mask = tokenized[\"attention_mask\"]\n",
    "\n",
    "    labels = input_ids.clone()\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids.to(device),\n",
    "        \"attention_mask\": attention_mask.to(device),\n",
    "        \"labels\": labels.to(device),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:49.520539Z",
     "iopub.status.busy": "2025-02-23T03:53:49.520208Z",
     "iopub.status.idle": "2025-02-23T03:53:49.525007Z",
     "shell.execute_reply": "2025-02-23T03:53:49.524263Z",
     "shell.execute_reply.started": "2025-02-23T03:53:49.520512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_ds.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:59.143483Z",
     "iopub.status.busy": "2025-02-23T03:53:59.143164Z",
     "iopub.status.idle": "2025-02-23T03:53:59.147758Z",
     "shell.execute_reply": "2025-02-23T03:53:59.146945Z",
     "shell.execute_reply.started": "2025-02-23T03:53:59.143458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_ds, batch_size=4, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=4, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:53:59.520082Z",
     "iopub.status.busy": "2025-02-23T03:53:59.519852Z",
     "iopub.status.idle": "2025-02-23T03:53:59.526923Z",
     "shell.execute_reply": "2025-02-23T03:53:59.526017Z",
     "shell.execute_reply.started": "2025-02-23T03:53:59.520062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:54:00.482729Z",
     "iopub.status.busy": "2025-02-23T03:54:00.482394Z",
     "iopub.status.idle": "2025-02-23T03:54:00.486502Z",
     "shell.execute_reply": "2025-02-23T03:54:00.485608Z",
     "shell.execute_reply.started": "2025-02-23T03:54:00.482704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.data = param.data.to(device)\n",
    "    if param.grad is not None:\n",
    "        param.grad.data = param.grad.data.to(device)\n",
    "\n",
    "# import bitsandbytes as bnb\n",
    "# for name, module in model.named_modules():\n",
    "#     if isinstance(module, bnb.nn.Linear4bit):\n",
    "#         module.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen2ForCausalLM(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(151936, 1536)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "              (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "              (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (rotary_emb): Qwen2RotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torch.compile(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T03:54:30.992256Z",
     "iopub.status.busy": "2025-02-23T03:54:30.991943Z",
     "iopub.status.idle": "2025-02-23T14:24:21.191339Z",
     "shell.execute_reply": "2025-02-23T14:24:21.190332Z",
     "shell.execute_reply.started": "2025-02-23T03:54:30.992233Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b44030c30745a3923fc0c1d51869e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a6c8273a6145a49402e9ec7d38c916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 1000, Loss: 0.9099\n",
      "Validation Loss at Step 1000, Loss: 1.0337\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d59e217d184bb791b2a32164010b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 2000, Loss: 0.7285\n",
      "Validation Loss at Step 2000, Loss: 0.8711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39f18dfa4a849e99e5dd6f537cd97c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 3000, Loss: 0.7271\n",
      "Validation Loss at Step 3000, Loss: 0.8420\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd6bb5540e342b48ae3d6075c8e9a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 4000, Loss: 1.2774\n",
      "Validation Loss at Step 4000, Loss: 0.8237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3764e34024614717aa9e91b739b230ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 5000, Loss: 0.6474\n",
      "Validation Loss at Step 5000, Loss: 0.8092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5356a626424d84b6ba358cda9681d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 6000, Loss: 0.8588\n",
      "Validation Loss at Step 6000, Loss: 0.8005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4222fc998a944ba5ba16117b98c18f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 7000, Loss: 0.7774\n",
      "Validation Loss at Step 7000, Loss: 0.7914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c6eef604cb48a18d2130f97ffcf8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 8000, Loss: 0.7733\n",
      "Validation Loss at Step 8000, Loss: 0.7867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585cf22f9fd84b60b864e20526310c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 9000, Loss: 0.8121\n",
      "Validation Loss at Step 9000, Loss: 0.7801\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6150abbde8e3462db49dadea93049f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 10000, Loss: 0.7961\n",
      "Validation Loss at Step 10000, Loss: 0.7755\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3417d26d12a4710a90086c5a35de70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 11000, Loss: 0.8418\n",
      "Validation Loss at Step 11000, Loss: 0.7707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3723554c1c3e45e0a3ec29b2df0824eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 12000, Loss: 0.6378\n",
      "Validation Loss at Step 12000, Loss: 0.7660\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a44c41b32964436a26b435bebc81f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 13000, Loss: 0.8803\n",
      "Validation Loss at Step 13000, Loss: 0.7627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf75b0fb746544b39763052e376652f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 14000, Loss: 0.8372\n",
      "Validation Loss at Step 14000, Loss: 0.7584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188e65792ce14f2abe723a83781ff289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 15000, Loss: 0.7096\n",
      "Validation Loss at Step 15000, Loss: 0.7550\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7e03548b2e4f1fb059ee0c9e388e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 16000, Loss: 0.7774\n",
      "Validation Loss at Step 16000, Loss: 0.7499\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e2c90a62e7444ca7ec0e42e7bff6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 17000, Loss: 0.7064\n",
      "Validation Loss at Step 17000, Loss: 0.7476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a842bb1d51f84d38b911d684af41bb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 18000, Loss: 0.7326\n",
      "Validation Loss at Step 18000, Loss: 0.7450\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67a07d2b04a4928966aa3be40208d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 19000, Loss: 0.6601\n",
      "Validation Loss at Step 19000, Loss: 0.7427\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a262d6b171d4c4183a42c25e2ea542c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 20000, Loss: 0.6647\n",
      "Validation Loss at Step 20000, Loss: 0.7393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5f3de8cacc422399d9ab468d2372db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 21000, Loss: 0.7790\n",
      "Validation Loss at Step 21000, Loss: 0.7377\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15f2aee83354d589b2eec9879b90299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 22000, Loss: 0.7667\n",
      "Validation Loss at Step 22000, Loss: 0.7368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f86cc880074271ac2e40bc30b3c109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 23000, Loss: 0.7260\n",
      "Validation Loss at Step 23000, Loss: 0.7332\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c669ada764ad49328335cee9bad29c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 24000, Loss: 0.6476\n",
      "Validation Loss at Step 24000, Loss: 0.7312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1fe86c52a4472d974391d1efbbcef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at Step 25000, Loss: 0.6084\n",
      "Validation Loss at Step 25000, Loss: 0.7292\n"
     ]
    }
   ],
   "source": [
    "gradient_accumulation_steps = 4\n",
    "batch_size = 1\n",
    "\n",
    "for step, batch in tqdm.notebook.tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    \n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    loss = loss / gradient_accumulation_steps\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "    if (step + 1) % gradient_accumulation_steps == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if (step + 1) % 1000 == 0:\n",
    "        training_loss = loss.item() * 4\n",
    "        \n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "\n",
    "        for val_step, val_batch in tqdm.notebook.tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            val_batch = {k: v.to(device) for k, v in val_batch.items()}\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(**val_batch)\n",
    "                val_loss = val_outputs.loss\n",
    "                total_loss += val_loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(valid_dataloader)\n",
    "        print(f\"Training Loss at Step {step+1}, Loss: {training_loss:.4f}\")\n",
    "        print(f\"Validation Loss at Step {step+1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_description = \"\"\"\n",
    "Table Descriptions:\n",
    "\n",
    "Table: yclamujetf (Customer Table)\n",
    "bhwqyackvb (INTEGER)\n",
    "Customer Identifier: A unique identifier for each customer.\n",
    "\n",
    "yjkfcsqlsb (TEXT)\n",
    "First Name: The customer's given name.\n",
    "\n",
    "tqnwzgbtgf (TEXT)\n",
    "Last Name: The customer's family name.\n",
    "\n",
    "taeatbvlbq (TEXT)\n",
    "Email: The customer's email address.\n",
    "\n",
    "vpkrulppkd (TEXT)\n",
    "Phone: The customer's contact phone number.\n",
    "\n",
    "obbvxwwzqg (TEXT)\n",
    "Address: The customer's residential or mailing address.\n",
    "\n",
    "fshvmouozp (DATE)\n",
    "Date of Birth: The customer's birth date.\n",
    "\n",
    "pfwsrivqwb (TEXT)\n",
    "SSN: The customer's Social Security Number (or other national identifier).\n",
    "\n",
    "qpkmhrxtbc (INTEGER)\n",
    "Credit Score: A numerical value representing the customer's creditworthiness.\n",
    "\n",
    "aslwxlorcs (TIMESTAMP)\n",
    "Created At: The timestamp marking when the customer record was created.\n",
    "\n",
    "Table: branches\n",
    "branch_id\n",
    "Branch Identifier: A unique identifier for each branch.\n",
    "\n",
    "branch_name\n",
    "Branch Name: The official name of the branch.\n",
    "\n",
    "address\n",
    "Street Address: The physical street address of the branch.\n",
    "\n",
    "city\n",
    "City: The city in which the branch is located.\n",
    "\n",
    "state\n",
    "State/Region: The state or region where the branch operates.\n",
    "\n",
    "zip_code\n",
    "ZIP/Postal Code: The postal code for the branch location.\n",
    "\n",
    "phone\n",
    "Phone Number: Contact telephone number for the branch.\n",
    "\n",
    "Table: accounts\n",
    "account_id\n",
    "Account Identifier: A unique identifier for each account.\n",
    "\n",
    "customer_id\n",
    "Customer Link: The identifier that links the account to a customer (from yclamujetf).\n",
    "\n",
    "branch_id\n",
    "Branch Link: The identifier of the branch where the account was opened or is maintained.\n",
    "\n",
    "account_type\n",
    "Type of Account: Specifies the kind of account (e.g., checking, savings).\n",
    "\n",
    "account_number\n",
    "Account Number: The official number assigned to the account.\n",
    "\n",
    "balance\n",
    "Current Balance: The current monetary balance of the account.\n",
    "\n",
    "status\n",
    "Account Status: Indicates the current state of the account (e.g., active, closed).\n",
    "\n",
    "opened_date\n",
    "Opened Date: The date on which the account was opened.\n",
    "\n",
    "Table: cards\n",
    "card_id\n",
    "Card Identifier: A unique identifier for each card.\n",
    "\n",
    "account_id\n",
    "Associated Account: The identifier for the account to which the card is linked.\n",
    "\n",
    "card_number\n",
    "Card Number: The number printed on the card.\n",
    "\n",
    "card_type\n",
    "Type of Card: The category of the card (e.g., credit, debit).\n",
    "\n",
    "expiry_date\n",
    "Expiry Date: The expiration date of the card.\n",
    "\n",
    "cvv\n",
    "CVV: The Card Verification Value (security code).\n",
    "\n",
    "status\n",
    "Card Status: The current status of the card (e.g., active, blocked).\n",
    "\n",
    "Table: loans\n",
    "loan_id\n",
    "Loan Identifier: A unique identifier for each loan.\n",
    "\n",
    "customer_id\n",
    "Customer Link: The identifier linking the loan to a customer (from yclamujetf).\n",
    "\n",
    "branch_id\n",
    "Branch Link: The identifier of the branch that processed or services the loan.\n",
    "\n",
    "loan_type\n",
    "Type of Loan: Specifies the loan category (e.g., personal, auto, mortgage).\n",
    "\n",
    "loan_amount\n",
    "Loan Amount: The total amount of money borrowed.\n",
    "\n",
    "interest_rate\n",
    "Interest Rate: The rate at which interest accrues on the loan.\n",
    "\n",
    "term_months\n",
    "Loan Term: The duration of the loan in months.\n",
    "\n",
    "monthly_payment\n",
    "Monthly Payment: The scheduled payment amount due each month.\n",
    "\n",
    "remaining_balance\n",
    "Remaining Balance: The outstanding amount yet to be paid.\n",
    "\n",
    "start_date\n",
    "Start Date: The date when the loan began.\n",
    "\n",
    "end_date\n",
    "End Date: The scheduled or actual date when the loan is to be or was fully repaid.\n",
    "\n",
    "status\n",
    "Loan Status: The current state of the loan (e.g., active, closed, default).\n",
    "\n",
    "Table: transactions\n",
    "transaction_id\n",
    "Transaction Identifier: A unique identifier for each transaction.\n",
    "\n",
    "account_id\n",
    "Associated Account: The identifier of the account related to the transaction.\n",
    "\n",
    "transaction_type\n",
    "Type of Transaction: Indicates the nature of the transaction (e.g., deposit, withdrawal, transfer).\n",
    "\n",
    "amount\n",
    "Amount: The monetary value involved in the transaction.\n",
    "\n",
    "transaction_date\n",
    "Transaction Date: The date and time when the transaction occurred.\n",
    "\n",
    "description\n",
    "Description: Additional details or context about the transaction.\n",
    "\n",
    "status\n",
    "Transaction Status: Indicates the current status (e.g., completed, pending, failed).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T14:24:46.870422Z",
     "iopub.status.busy": "2025-02-23T14:24:46.870100Z",
     "iopub.status.idle": "2025-02-23T14:24:46.876478Z",
     "shell.execute_reply": "2025-02-23T14:24:46.875341Z",
     "shell.execute_reply.started": "2025-02-23T14:24:46.870397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_text_stream(model, tokenizer, prompt, device, max_new_tokens=100):\n",
    "    \"\"\"\n",
    "    Streams generated text token-by-token using the model's forward pass with caching.\n",
    "    This avoids the tensor size mismatch error by properly handling past_key_values.\n",
    "    \"\"\"\n",
    "    system_prompt = \"You are an AI that translates natural language into SQL queries. You will output only the SQL query that outputs the following natural language question. Give me response in one single SQL query.\"\n",
    "    system_prompt = f\"{system_prompt}\\n{table_description}\\n\"\n",
    "    full_prompt = f\"{system_prompt}\\nQuestion:\\n{prompt} {tokenizer.eos_token}\\n SQL Query:\\n\"\n",
    "\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    \n",
    "    past_key_values = None\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            if past_key_values is None:\n",
    "                outputs = model(input_ids=generated_ids, attention_mask=attention_mask, use_cache=True)\n",
    "            else:\n",
    "                outputs = model(\n",
    "                    input_ids=generated_ids[:, -1].unsqueeze(-1),\n",
    "                    attention_mask=attention_mask,\n",
    "                    use_cache=True,\n",
    "                    past_key_values=past_key_values\n",
    "                )\n",
    "                \n",
    "            logits = outputs.logits\n",
    "            past_key_values = outputs.past_key_values if hasattr(outputs, \"past_key_values\") else None\n",
    "            \n",
    "            next_token_logits = logits[:, -1, :]\n",
    "            next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "            next_token = torch.multinomial(next_token_probs, num_samples=1)\n",
    "            \n",
    "            generated_ids = torch.cat([generated_ids, next_token], dim=1)\n",
    "            attention_mask = torch.cat([attention_mask, torch.ones((attention_mask.shape[0], 1), dtype=attention_mask.dtype, device=device)], dim=1)\n",
    "            \n",
    "            token = tokenizer.decode(next_token.squeeze(), skip_special_tokens=True)\n",
    "            yield token\n",
    "\n",
    "            if next_token.item() == tokenizer.eos_token_id:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T14:24:48.840963Z",
     "iopub.status.busy": "2025-02-23T14:24:48.840607Z",
     "iopub.status.idle": "2025-02-23T14:25:03.590106Z",
     "shell.execute_reply": "2025-02-23T14:25:03.589244Z",
     "shell.execute_reply.started": "2025-02-23T14:24:48.840936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT c1.customer_id, c1.balance, SUM(c2.balance) FROM accounts a1 JOIN cards c2 ON a1.account_id = c2.account_id JOIN loans l ON c2.account_id = l.account_id); SELECT c1.customer_id, c1.balance FROM customers WHERE c1.customer_id NOT IN (SELECT customer_id FROM accounts JOIN transactions ON accounts.account_id = transactions.account_id WHERE (c2.account_id, c2.amount) IN (inspect_products(c, transactions) WHERE"
     ]
    }
   ],
   "source": [
    "prompt = \"Find customers who have multiple accounts and their total balance across all accounts.\"\n",
    "for token in generate_text_stream(model, tokenizer, prompt, device):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T14:25:19.524277Z",
     "iopub.status.busy": "2025-02-23T14:25:19.523929Z",
     "iopub.status.idle": "2025-02-23T14:25:19.873170Z",
     "shell.execute_reply": "2025-02-23T14:25:19.872282Z",
     "shell.execute_reply.started": "2025-02-23T14:25:19.524250Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT/tokenizer_config.json',\n",
       " 'DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT/special_tokens_map.json',\n",
       " 'DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT/tokenizer.json')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT\")\n",
    "tokenizer.save_pretrained(\"DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T14:25:36.744687Z",
     "iopub.status.busy": "2025-02-23T14:25:36.744324Z",
     "iopub.status.idle": "2025-02-23T14:25:40.579728Z",
     "shell.execute_reply": "2025-02-23T14:25:40.579010Z",
     "shell.execute_reply.started": "2025-02-23T14:25:36.744633Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/NotShrirang/DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT/commit/a92cdb32b6745e9cfaa0950c9d475ba2ab4b4e66', commit_message='Upload tokenizer', commit_description='', oid='a92cdb32b6745e9cfaa0950c9d475ba2ab4b4e66', pr_url=None, repo_url=RepoUrl('https://huggingface.co/NotShrirang/DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT', endpoint='https://huggingface.co', repo_type='model', repo_id='NotShrirang/DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "HF_TOKEN = \"\"\n",
    "\n",
    "repo_name = \"NotShrirang/DeepSeek-R1-Distill-Qwen-1.5B-SQL-Coder-PEFT\"\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "api.create_repo(repo_id=repo_name, exist_ok=True)\n",
    "\n",
    "model.push_to_hub(repo_name, token=HF_TOKEN)\n",
    "tokenizer.push_to_hub(repo_name, token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
